{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c596b0b1-8991-4ca3-a14e-b38548b1dd1d",
   "metadata": {},
   "source": [
    "Using `pykeen.ablation` instead of `pykeen.hpo` (https://pykeen.readthedocs.io/en/stable/tutorial/running_ablation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cc622c-18ce-4783-9276-3d87e7cc5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.ablation import ablation_pipeline\n",
    "import json\n",
    "\n",
    "output_dir = \"./test_ablation_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18a88bd9-b92f-4b63-93af-b72a6f8082bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RotatE\", \"TransE\"]\n",
    "\n",
    "ablation_config = {\n",
    "    \"metadata\": {\n",
    "        \"title\": \"Ablation Study Over Nations for ComplEx.\"\n",
    "    },\n",
    "    \"ablation\": {\n",
    "        #\"datasets\": [\"nations\"],\n",
    "        \"epochs\": 100,\n",
    "        \"models\":  models,\n",
    "        \"losses\": [\"MarginRankingLoss\", \"NSSALoss\"], # sec 7.4 'impact of the loss function'\n",
    "        \"training_loops\": [\"sLCWA\"], # just use sLCWA as LCWA expensive (paper sec. 7 -> training approaches)\n",
    "        \"optimizers\": [\"adam\"],\n",
    "        \"negative_sampler\": \"BasicNegativeSampler\",\n",
    "        \"create_inverse_triples\": [True, False],\n",
    "        \"stopper\": \"early\",\n",
    "        \"stopper_kwargs\": {\n",
    "            \"frequency\": 10,\n",
    "            \"patience\": 20,\n",
    "            \"relative_delta\": 0.002,\n",
    "            \"metric\": \"hits@10\"\n",
    "        },\n",
    "        \"model_to_model_kwargs_ranges\": {\n",
    "            model: {\n",
    "                \"embedding_dim\": {\n",
    "                    \"type\": \"int\", \n",
    "                    \"low\": 6, # = 64\n",
    "                    \"high\": 8, #Â = 256\n",
    "                    \"scale\": \"power_two\"\n",
    "                }\n",
    "            } for model in models\n",
    "        },\n",
    "        \"model_to_training_loop_to_training_kwargs_ranges\": {\n",
    "            model: {\n",
    "                \"sLCWA\": {\n",
    "                    \"batch_size\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"low\": 10, # 1024\n",
    "                        \"high\": 13, # 8192\n",
    "                        \"scale\": \"power_two\"\n",
    "                    }\n",
    "                }\n",
    "            } for model in models\n",
    "        },\n",
    "        \"model_to_optimizer_to_optimizer_kwargs_ranges\": {\n",
    "            model : {\n",
    "                \"adam\": {\n",
    "                    \"lr\": {\n",
    "                        \"type\": \"float\",\n",
    "                        \"low\": 0.001,\n",
    "                        \"high\": 0.1,\n",
    "                        \"scale\": \"log\"\n",
    "                    }\n",
    "                }\n",
    "            } for model in models\n",
    "        },\n",
    "        \"model_to_loss_to_loss_kwargs_ranges\": {\n",
    "            model: {\n",
    "                \"MarginRankingLoss\": {\n",
    "                    \"margin\": {\n",
    "                        \"type\": \"categorical\",\n",
    "                        \"choices\": [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5],\n",
    "                    }\n",
    "                },\n",
    "                \"NSSALoss\": {\n",
    "                    \"margin\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"low\": 1,\n",
    "                        \"high\": 29,\n",
    "                        \"q\": 2\n",
    "                    },\n",
    "                    \"adversarial_temperature\": {\n",
    "                        \"type\": \"float\",\n",
    "                        \"low\": 0.1,\n",
    "                        \"high\": 1,\n",
    "                        \"q\": 0.1\n",
    "                    }\n",
    "                }\n",
    "            } for model in models\n",
    "        },\n",
    "        \"model_to_negative_sampler_to_negative_sampler_kwargs_ranges\": {\n",
    "            model: {\n",
    "                \"basic\": {\n",
    "                    \"num_negs_per_pos\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"low\": 1,\n",
    "                        \"high\": 50,\n",
    "                        \"q\": 1\n",
    "                    }\n",
    "                }\n",
    "            } for model in models\n",
    "        }\n",
    "    },\n",
    "    \"optuna\": {\n",
    "        \"n_trials\": 2,\n",
    "#         \"timeout\": 300,\n",
    "        \"metric\": \"hits@10\",\n",
    "        \"direction\": \"maximize\",\n",
    "        \"sampler\": \"random\",\n",
    "        \"pruner\": \"nop\"\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0295eca6-5558-4e6f-9dfd-a6332723e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: True\n",
      "INFO:pykeen.ablation.ablation:Model: RotatE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: MarginRankingLoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: True\n",
      "INFO:pykeen.ablation.ablation:Model: RotatE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: NSSALoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: True\n",
      "INFO:pykeen.ablation.ablation:Model: TransE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: MarginRankingLoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: True\n",
      "INFO:pykeen.ablation.ablation:Model: TransE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: NSSALoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: False\n",
      "INFO:pykeen.ablation.ablation:Model: RotatE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: MarginRankingLoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: False\n",
      "INFO:pykeen.ablation.ablation:Model: RotatE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: NSSALoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: False\n",
      "INFO:pykeen.ablation.ablation:Model: TransE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: MarginRankingLoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "INFO:pykeen.ablation.ablation:Dataset: nations\n",
      "INFO:pykeen.ablation.ablation:Add inverse triples: False\n",
      "INFO:pykeen.ablation.ablation:Model: TransE\n",
      "INFO:pykeen.ablation.ablation:Loss functions: NSSALoss\n",
      "INFO:pykeen.ablation.ablation:Optimizer: adam\n",
      "INFO:pykeen.ablation.ablation:Training loop: sLCWA\n",
      "INFO:pykeen.ablation.ablation:Negative sampler: BasicNegativeSampler\n",
      "INFO:pykeen.ablation.ablation:Evaluator: None\n",
      "\u001b[32m[I 2021-07-06 16:17:51,541]\u001b[0m A new study created in RDB with name: no-name-c200880f-5eb4-4222-b0ae-b1da8dc41abd\u001b[0m\n",
      "INFO:pykeen.hpo.hpo:Using model: <class 'pykeen.models.unimodal.rotate.RotatE'>\n",
      "INFO:pykeen.hpo.hpo:Using loss: <class 'pykeen.losses.MarginRankingLoss'>\n",
      "INFO:pykeen.hpo.hpo:Using optimizer: <class 'torch.optim.adam.Adam'>\n",
      "INFO:pykeen.hpo.hpo:Using training loop: <class 'pykeen.training.slcwa.SLCWATrainingLoop'>\n",
      "INFO:pykeen.hpo.hpo:Using negative sampler: <class 'pykeen.sampling.basic_negative_sampler.BasicNegativeSampler'>\n",
      "INFO:pykeen.hpo.hpo:Using evaluator: <class 'pykeen.evaluation.rank_based_evaluator.RankBasedEvaluator'>\n",
      "INFO:pykeen.hpo.hpo:Attempting to maximize hits@10\n",
      "INFO:pykeen.hpo.hpo:Filter validation triples when testing: True\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1873090495.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.triples.triples_factory:Creating inverse triples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int power_two embedding_dim 64\n",
      "categorical None margin 5.5\n",
      "categorical None margin_activation softplus\n",
      "float log lr 0.06335807923102385\n",
      "<class 'int'> None num_negs_per_pos 10\n",
      "num_epochs not suggested\n",
      "int power_two batch_size 2048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b7d08c0f434f139b4d982973a8a977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.01s seconds\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.01s seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c492755f544c32b29c71876ff71367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nv/ml84yvj11ns_bxrq3c40q2xc0000gn/T/ipykernel_20331/3464911653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mablation_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./ablation_tests_2\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mablation_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ablation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mablation_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optuna\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/ablation/ablation.py\u001b[0m in \u001b[0;36mablation_pipeline\u001b[0;34m(datasets, directory, models, losses, optimizers, training_loops, epochs, create_inverse_triples, regularizers, negative_sampler, evaluator, stopper, model_to_model_kwargs, model_to_model_kwargs_ranges, model_to_loss_to_loss_kwargs, model_to_loss_to_loss_kwargs_ranges, model_to_optimizer_to_optimizer_kwargs, model_to_optimizer_to_optimizer_kwargs_ranges, model_to_negative_sampler_to_negative_sampler_kwargs, model_to_negative_sampler_to_negative_sampler_kwargs_ranges, model_to_training_loop_to_training_loop_kwargs, model_to_training_loop_to_training_kwargs, model_to_training_loop_to_training_kwargs_ranges, model_to_regularizer_to_regularizer_kwargs, model_to_regularizer_to_regularizer_kwargs_ranges, evaluator_kwargs, evaluation_kwargs, stopper_kwargs, n_trials, timeout, metric, direction, sampler, pruner, metadata, save_artifacts, move_to_cpu, dry_run, best_replicates, discard_replicates, create_unique_subdir)\u001b[0m\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     _run_ablation_experiments(\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mdirectories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirectories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mbest_replicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_replicates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/ablation/ablation.py\u001b[0m in \u001b[0;36m_run_ablation_experiments\u001b[0;34m(directories, best_replicates, dry_run, move_to_cpu, discard_replicates)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0moutput_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mhpo_pipeline_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_pipeline_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv_config_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mhpo_pipeline_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/hpo/hpo.py\u001b[0m in \u001b[0;36mhpo_pipeline_from_path\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhpo_pipeline_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/hpo/hpo.py\u001b[0m in \u001b[0;36mhpo_pipeline_from_config\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhpo_pipeline_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mHpoPipelineResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;34m\"\"\"Run the HPO pipeline using a properly formatted configuration dictionary.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     return hpo_pipeline(\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pipeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optuna'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/hpo/hpo.py\u001b[0m in \u001b[0;36mhpo_pipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, model_kwargs_ranges, loss, loss_kwargs, loss_kwargs_ranges, regularizer, regularizer_kwargs, regularizer_kwargs_ranges, optimizer, optimizer_kwargs, optimizer_kwargs_ranges, lr_scheduler, lr_scheduler_kwargs, lr_scheduler_kwargs_ranges, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, negative_sampler_kwargs_ranges, epochs, training_kwargs, training_kwargs_ranges, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, metric, filter_validation_when_testing, result_tracker, result_tracker_kwargs, device, storage, sampler, sampler_kwargs, pruner, pruner_kwargs, study_name, direction, load_if_exists, n_trials, timeout, n_jobs, save_model_directory)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;31m# Invoke optimization of the objective function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     study.optimize(\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/hcvectors/lib/python3.9/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/hcvectors/lib/python3.9/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/hcvectors/lib/python3.9/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/hcvectors/lib/python3.9/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/hpo/hpo.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             result = pipeline(\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# 1. Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/pipeline/api.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;31m# Train like Cristiano Ronaldo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m     losses = training_loop_instance.train(\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0mtriples_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mstopper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopper_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_per_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             result = self._train(\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, triples_factory, training_instances, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, result_tracker, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                         \u001b[0;31m# forward pass call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                         batch_loss = self._forward_pass(\n\u001b[0m\u001b[1;32m    623\u001b[0m                             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    770\u001b[0m     ) -> float:\n\u001b[1;32m    771\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         loss = self._process_batch(\n\u001b[0m\u001b[1;32m    773\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/training/slcwa.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, batch, start, stop, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Compute negative and positive scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mpositive_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_hrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mnegative_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_hrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnegative_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         return self.loss.process_slcwa_scores(\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/models/unimodal/rotate.py\u001b[0m in \u001b[0;36mscore_hrt\u001b[0;34m(self, hrt_batch)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Compute scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Embedding Regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SMG/pykeen/src/pykeen/models/unimodal/rotate.py\u001b[0m in \u001b[0;36minteraction_function\u001b[0;34m(h, r, t)\u001b[0m\n\u001b[1;32m    111\u001b[0m         rot_h = torch.stack(\n\u001b[1;32m    112\u001b[0m             [\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mh_re\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_re\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh_im\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_im\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mh_re\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_im\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_im\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_re\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             ],\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ablation_pipeline(\"nations\", \"./ablation_tests_2\" , **ablation_config[\"ablation\"], **ablation_config[\"optuna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c85b5d30-d2ed-419c-a273-9e49c64de11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: True\n",
      "2021-07-06 16:14:43 INFO     Model: RotatE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: MarginRankingLoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: True\n",
      "2021-07-06 16:14:43 INFO     Model: RotatE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: NSSALoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: True\n",
      "2021-07-06 16:14:43 INFO     Model: TransE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: MarginRankingLoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: True\n",
      "2021-07-06 16:14:43 INFO     Model: TransE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: NSSALoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: False\n",
      "2021-07-06 16:14:43 INFO     Model: RotatE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: MarginRankingLoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: False\n",
      "2021-07-06 16:14:43 INFO     Model: RotatE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: NSSALoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: False\n",
      "2021-07-06 16:14:43 INFO     Model: TransE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: MarginRankingLoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "2021-07-06 16:14:43 INFO     Dataset: nations\n",
      "2021-07-06 16:14:43 INFO     Add inverse triples: False\n",
      "2021-07-06 16:14:43 INFO     Model: TransE\n",
      "2021-07-06 16:14:43 INFO     Loss functions: NSSALoss\n",
      "2021-07-06 16:14:43 INFO     Optimizer: adam\n",
      "2021-07-06 16:14:43 INFO     Training loop: sLCWA\n",
      "2021-07-06 16:14:43 INFO     Negative sampler: BasicNegativeSampler\n",
      "2021-07-06 16:14:43 INFO     Evaluator: None\n",
      "\u001b[32m[I 2021-07-06 16:14:43,584]\u001b[0m A new study created in RDB with name: no-name-5948f9fc-c08a-4c3d-9bce-8ff8e3ec552e\u001b[0m\n",
      "2021-07-06 16:14:43 INFO     Using model: <class 'pykeen.models.unimodal.rotate.RotatE'>\n",
      "2021-07-06 16:14:43 INFO     Using loss: <class 'pykeen.losses.MarginRankingLoss'>\n",
      "2021-07-06 16:14:43 INFO     Using optimizer: <class 'torch.optim.adam.Adam'>\n",
      "2021-07-06 16:14:43 INFO     Using training loop: <class 'pykeen.training.slcwa.SLCWATrainingLoop'>\n",
      "2021-07-06 16:14:43 INFO     Using negative sampler: <class 'pykeen.sampling.basic_negative_sampler.BasicNegativeSampler'>\n",
      "2021-07-06 16:14:43 INFO     Using evaluator: <class 'pykeen.evaluation.rank_based_evaluator.RankBasedEvaluator'>\n",
      "2021-07-06 16:14:43 INFO     Attempting to maximize hits@10\n",
      "2021-07-06 16:14:43 INFO     Filter validation triples when testing: True\n",
      "int power_two embedding_dim 128\n",
      "categorical None margin 0.5\n",
      "categorical None margin_activation relu\n",
      "float log lr 0.06271895743070736\n",
      "<class 'int'> None num_negs_per_pos 1\n",
      "num_epochs not suggested\n",
      "int power_two batch_size 8192\n",
      "2021-07-06 16:14:43 WARNING  No random seed is specified. Setting to 3472360177.\n",
      "2021-07-06 16:14:43 WARNING  No cuda devices were available. The model runs on CPU\n",
      "2021-07-06 16:14:43 INFO     Creating inverse triples.\n",
      "Training epochs on cpu:   0%|                        | 0/500 [00:00<?, ?epoch/s]\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   0%| | 1/500 [00:00<01:19,  6.29epoch/s, loss=0.000156,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   0%| | 2/500 [00:00<01:11,  6.97epoch/s, loss=0.000187,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 3/500 [00:00<01:09,  7.12epoch/s, loss=0.00015, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 4/500 [00:00<01:07,  7.40epoch/s, loss=0.000151,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 5/500 [00:00<01:07,  7.33epoch/s, loss=0.000144,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 6/500 [00:00<01:08,  7.20epoch/s, loss=0.000134,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 7/500 [00:00<01:07,  7.29epoch/s, loss=0.000133,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 8/500 [00:01<01:07,  7.33epoch/s, loss=0.00013, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 9/500 [00:01<01:05,  7.50epoch/s, loss=0.000122,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 9/500 [00:01<01:05,  7.50epoch/s, loss=0.000119,2021-07-06 16:14:45 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:45 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:45 INFO     Evaluation took 0.02s seconds\n",
      "2021-07-06 16:14:45 INFO     => Saved checkpoint after having finished epoch 10.\n",
      "Training epochs on cpu:   2%| | 10/500 [00:01<01:08,  7.12epoch/s, loss=0.000119\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 11/500 [00:01<01:08,  7.18epoch/s, loss=0.000115\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 12/500 [00:01<01:07,  7.26epoch/s, loss=0.000112\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 13/500 [00:01<01:05,  7.40epoch/s, loss=0.000107\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 14/500 [00:01<01:03,  7.65epoch/s, loss=0.000102\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 15/500 [00:02<01:01,  7.87epoch/s, loss=0.000101\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 16/500 [00:02<00:58,  8.27epoch/s, loss=9.87e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 17/500 [00:02<00:56,  8.54epoch/s, loss=9.2e-5, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 18/500 [00:02<00:55,  8.73epoch/s, loss=9.07e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 19/500 [00:02<00:53,  8.92epoch/s, loss=8.7e-5, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 19/500 [00:02<00:53,  8.92epoch/s, loss=8.68e-5,\u001b[A2021-07-06 16:14:46 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:46 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:46 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:   4%| | 20/500 [00:02<00:55,  8.62epoch/s, loss=8.68e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 21/500 [00:02<00:54,  8.78epoch/s, loss=8.2e-5, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 22/500 [00:02<00:53,  8.94epoch/s, loss=8.18e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 23/500 [00:02<00:53,  8.92epoch/s, loss=8.14e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 24/500 [00:03<00:53,  8.92epoch/s, loss=7.63e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 25/500 [00:03<00:52,  9.01epoch/s, loss=7.33e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 26/500 [00:03<00:52,  9.05epoch/s, loss=7.41e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 27/500 [00:03<00:52,  8.97epoch/s, loss=7.54e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 28/500 [00:03<00:51,  9.08epoch/s, loss=6.91e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 29/500 [00:03<00:52,  9.00epoch/s, loss=6.97e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 29/500 [00:03<00:52,  9.00epoch/s, loss=6.75e-5,2021-07-06 16:14:47 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:47 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:47 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:   6%| | 30/500 [00:03<00:55,  8.54epoch/s, loss=6.75e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 31/500 [00:03<00:54,  8.57epoch/s, loss=6.57e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 32/500 [00:03<00:54,  8.63epoch/s, loss=6.71e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 33/500 [00:04<00:52,  8.81epoch/s, loss=6.48e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 34/500 [00:04<00:53,  8.79epoch/s, loss=6.3e-5, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 35/500 [00:04<00:53,  8.76epoch/s, loss=6.14e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 36/500 [00:04<00:52,  8.80epoch/s, loss=6.09e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 37/500 [00:04<00:53,  8.69epoch/s, loss=6.02e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 38/500 [00:04<00:53,  8.71epoch/s, loss=6.11e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 39/500 [00:04<00:52,  8.80epoch/s, loss=5.98e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 39/500 [00:04<00:52,  8.80epoch/s, loss=5.87e-5,2021-07-06 16:14:48 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:48 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:48 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:   8%| | 40/500 [00:04<00:54,  8.46epoch/s, loss=5.87e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 41/500 [00:04<00:53,  8.65epoch/s, loss=5.84e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 42/500 [00:05<00:51,  8.81epoch/s, loss=5.66e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 43/500 [00:05<00:52,  8.74epoch/s, loss=5.84e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 44/500 [00:05<00:51,  8.86epoch/s, loss=5.57e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 45/500 [00:05<00:51,  8.86epoch/s, loss=5.63e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 46/500 [00:05<00:52,  8.72epoch/s, loss=5.51e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 47/500 [00:05<00:52,  8.65epoch/s, loss=5.31e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 48/500 [00:05<00:52,  8.54epoch/s, loss=5.56e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 49/500 [00:05<00:51,  8.75epoch/s, loss=5.54e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 49/500 [00:05<00:51,  8.75epoch/s, loss=5.53e-5,2021-07-06 16:14:49 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:49 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:49 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  10%| | 50/500 [00:06<00:53,  8.46epoch/s, loss=5.53e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 51/500 [00:06<00:51,  8.67epoch/s, loss=5.43e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 52/500 [00:06<00:50,  8.86epoch/s, loss=5.44e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 53/500 [00:06<00:49,  8.97epoch/s, loss=5.32e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 54/500 [00:06<00:49,  9.03epoch/s, loss=5.24e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 55/500 [00:06<00:49,  9.07epoch/s, loss=5.08e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 56/500 [00:06<00:49,  8.89epoch/s, loss=5.46e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 57/500 [00:06<00:49,  8.88epoch/s, loss=5.29e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 58/500 [00:06<00:49,  9.02epoch/s, loss=5.25e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 59/500 [00:07<00:49,  8.93epoch/s, loss=5.13e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 59/500 [00:07<00:49,  8.93epoch/s, loss=5e-5, pr2021-07-06 16:14:51 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:51 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:51 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  12%| | 60/500 [00:07<00:52,  8.36epoch/s, loss=5e-5, pr\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 61/500 [00:07<00:51,  8.54epoch/s, loss=5.15e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 62/500 [00:07<00:50,  8.68epoch/s, loss=5.04e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 63/500 [00:07<00:49,  8.86epoch/s, loss=4.84e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 64/500 [00:07<00:49,  8.86epoch/s, loss=5.01e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 65/500 [00:07<00:49,  8.75epoch/s, loss=5.12e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 66/500 [00:07<00:50,  8.66epoch/s, loss=4.83e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 67/500 [00:07<00:49,  8.78epoch/s, loss=5.06e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 68/500 [00:08<00:48,  8.83epoch/s, loss=5.05e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 69/500 [00:08<00:48,  8.91epoch/s, loss=4.85e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 69/500 [00:08<00:48,  8.91epoch/s, loss=4.87e-5,2021-07-06 16:14:52 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:52 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:52 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  14%|â| 70/500 [00:08<00:50,  8.59epoch/s, loss=4.87e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 71/500 [00:08<00:48,  8.78epoch/s, loss=4.9e-5, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 72/500 [00:08<00:48,  8.92epoch/s, loss=5.14e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 73/500 [00:08<00:47,  9.00epoch/s, loss=4.85e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 74/500 [00:08<00:46,  9.10epoch/s, loss=4.92e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 75/500 [00:08<00:46,  9.12epoch/s, loss=4.79e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 76/500 [00:08<00:46,  9.16epoch/s, loss=4.82e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 77/500 [00:09<00:45,  9.20epoch/s, loss=5.12e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|â| 78/500 [00:09<00:45,  9.21epoch/s, loss=4.68e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|â| 79/500 [00:09<00:46,  9.15epoch/s, loss=4.83e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|â| 79/500 [00:09<00:46,  9.15epoch/s, loss=4.93e-5,2021-07-06 16:14:53 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:53 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:53 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  16%|â| 80/500 [00:09<00:48,  8.73epoch/s, loss=4.93e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|â| 81/500 [00:09<00:47,  8.91epoch/s, loss=4.81e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|â| 82/500 [00:09<00:46,  9.02epoch/s, loss=4.76e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  17%|â| 83/500 [00:09<00:45,  9.10epoch/s, loss=4.81e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  17%|â| 84/500 [00:09<00:46,  9.03epoch/s, loss=4.9e-5, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  17%|â| 85/500 [00:09<00:45,  9.06epoch/s, loss=4.73e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  17%|â| 86/500 [00:10<00:45,  9.13epoch/s, loss=5.07e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  17%|â| 87/500 [00:10<00:44,  9.19epoch/s, loss=4.64e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|â| 88/500 [00:10<00:44,  9.18epoch/s, loss=4.88e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|â| 89/500 [00:10<00:45,  9.04epoch/s, loss=4.49e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|â| 89/500 [00:10<00:45,  9.04epoch/s, loss=4.67e-5,2021-07-06 16:14:54 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:54 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:54 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  18%|â| 90/500 [00:10<00:47,  8.63epoch/s, loss=4.67e-5,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|â| 91/500 [00:10<00:47,  8.55epoch/s, loss=4.76e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|â| 92/500 [00:10<00:46,  8.78epoch/s, loss=4.59e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  19%|â| 93/500 [00:10<00:45,  8.94epoch/s, loss=4.94e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  19%|â| 94/500 [00:10<00:45,  8.85epoch/s, loss=4.86e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  19%|â| 95/500 [00:11<00:45,  8.97epoch/s, loss=4.67e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  19%|â| 96/500 [00:11<00:45,  8.95epoch/s, loss=4.44e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  19%|â| 97/500 [00:11<00:45,  8.82epoch/s, loss=4.67e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|â| 98/500 [00:11<00:45,  8.83epoch/s, loss=4.63e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|â| 99/500 [00:11<00:44,  8.99epoch/s, loss=4.58e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|â| 99/500 [00:11<00:44,  8.99epoch/s, loss=4.64e-5,2021-07-06 16:14:55 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:55 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:55 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  20%|â| 100/500 [00:11<00:46,  8.59epoch/s, loss=4.64e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|â| 101/500 [00:11<00:45,  8.73epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|â| 102/500 [00:11<00:45,  8.68epoch/s, loss=4.37e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  21%|â| 103/500 [00:11<00:45,  8.73epoch/s, loss=4.82e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  21%|â| 104/500 [00:12<00:45,  8.77epoch/s, loss=4.67e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  21%|â| 105/500 [00:12<00:44,  8.89epoch/s, loss=4.84e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  21%|â| 106/500 [00:12<00:43,  8.99epoch/s, loss=4.63e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  21%|â| 107/500 [00:12<00:43,  9.05epoch/s, loss=4.66e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|â| 108/500 [00:12<00:44,  8.82epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|â| 109/500 [00:12<00:45,  8.65epoch/s, loss=4.72e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|â| 109/500 [00:12<00:45,  8.65epoch/s, loss=4.65e-5\u001b[A2021-07-06 16:14:56 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:56 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:56 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  22%|â| 110/500 [00:12<00:47,  8.16epoch/s, loss=4.65e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|â| 111/500 [00:12<00:47,  8.22epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|â| 112/500 [00:13<00:47,  8.16epoch/s, loss=4.47e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  23%|â| 113/500 [00:13<00:45,  8.41epoch/s, loss=4.8e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  23%|â| 114/500 [00:13<00:44,  8.63epoch/s, loss=4.77e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  23%|â| 115/500 [00:13<00:43,  8.79epoch/s, loss=4.54e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  23%|â| 116/500 [00:13<00:42,  9.00epoch/s, loss=4.91e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  23%|â| 117/500 [00:13<00:42,  9.10epoch/s, loss=4.61e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|â| 118/500 [00:13<00:41,  9.18epoch/s, loss=4.57e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|â| 119/500 [00:13<00:41,  9.14epoch/s, loss=4.5e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|â| 119/500 [00:13<00:41,  9.14epoch/s, loss=4.68e-5\u001b[A2021-07-06 16:14:57 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:57 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:57 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  24%|â| 120/500 [00:13<00:43,  8.75epoch/s, loss=4.68e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|â| 121/500 [00:14<00:42,  8.88epoch/s, loss=4.4e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|â| 122/500 [00:14<00:41,  9.00epoch/s, loss=4.59e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  25%|â| 123/500 [00:14<00:41,  9.06epoch/s, loss=4.72e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  25%|â| 124/500 [00:14<00:41,  9.10epoch/s, loss=4.53e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  25%|â| 125/500 [00:14<00:40,  9.15epoch/s, loss=5.01e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  25%|â| 126/500 [00:14<00:40,  9.20epoch/s, loss=4.72e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  25%|â| 127/500 [00:14<00:40,  9.15epoch/s, loss=4.56e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|â| 128/500 [00:14<00:40,  9.13epoch/s, loss=4.68e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|â| 129/500 [00:14<00:40,  9.07epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|â| 129/500 [00:15<00:40,  9.07epoch/s, loss=4.86e-52021-07-06 16:14:58 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:14:58 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:14:59 INFO     Evaluation took 0.02s seconds\n",
      "Training epochs on cpu:  26%|â| 130/500 [00:15<00:46,  7.93epoch/s, loss=4.86e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|â| 131/500 [00:15<00:45,  8.06epoch/s, loss=4.54e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|â| 132/500 [00:15<00:44,  8.22epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  27%|â| 133/500 [00:15<00:43,  8.37epoch/s, loss=4.73e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  27%|â| 134/500 [00:15<00:43,  8.43epoch/s, loss=4.78e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  27%|â| 135/500 [00:15<00:42,  8.51epoch/s, loss=4.48e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  27%|â| 136/500 [00:15<00:42,  8.51epoch/s, loss=4.51e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  27%|â| 137/500 [00:15<00:42,  8.46epoch/s, loss=4.59e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|â| 138/500 [00:15<00:42,  8.57epoch/s, loss=4.46e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|â| 139/500 [00:16<00:41,  8.66epoch/s, loss=4.7e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|â| 139/500 [00:16<00:41,  8.66epoch/s, loss=4.62e-52021-07-06 16:15:00 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:00 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:00 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  28%|â| 140/500 [00:16<00:43,  8.27epoch/s, loss=4.62e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|â| 141/500 [00:16<00:42,  8.38epoch/s, loss=4.56e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|â| 142/500 [00:16<00:42,  8.46epoch/s, loss=4.44e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  29%|â| 143/500 [00:16<00:41,  8.63epoch/s, loss=4.79e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  29%|â| 144/500 [00:16<00:40,  8.71epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  29%|â| 145/500 [00:16<00:40,  8.77epoch/s, loss=4.7e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  29%|â| 146/500 [00:16<00:40,  8.80epoch/s, loss=4.55e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  29%|â| 147/500 [00:17<00:39,  8.90epoch/s, loss=4.57e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|â| 148/500 [00:17<00:38,  9.03epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|â| 149/500 [00:17<00:38,  9.02epoch/s, loss=4.92e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|â| 149/500 [00:17<00:38,  9.02epoch/s, loss=4.57e-52021-07-06 16:15:01 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:01 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:01 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  30%|â| 150/500 [00:17<00:41,  8.44epoch/s, loss=4.57e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|â| 151/500 [00:17<00:41,  8.31epoch/s, loss=4.47e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|â| 152/500 [00:17<00:41,  8.29epoch/s, loss=4.44e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  31%|â| 153/500 [00:17<00:42,  8.12epoch/s, loss=4.7e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  31%|â| 154/500 [00:17<00:41,  8.29epoch/s, loss=4.59e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  31%|â| 155/500 [00:17<00:40,  8.42epoch/s, loss=4.75e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  31%|â| 156/500 [00:18<00:40,  8.43epoch/s, loss=4.5e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  31%|â| 157/500 [00:18<00:39,  8.61epoch/s, loss=4.68e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|â| 158/500 [00:18<00:38,  8.77epoch/s, loss=4.59e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|â| 159/500 [00:18<00:39,  8.69epoch/s, loss=4.49e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|â| 159/500 [00:18<00:39,  8.69epoch/s, loss=4.66e-52021-07-06 16:15:02 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:02 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:02 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  32%|â| 160/500 [00:18<00:40,  8.44epoch/s, loss=4.66e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|â| 161/500 [00:18<00:39,  8.59epoch/s, loss=4.61e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|â| 162/500 [00:18<00:38,  8.78epoch/s, loss=4.57e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  33%|â| 163/500 [00:18<00:37,  8.93epoch/s, loss=4.47e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  33%|â| 164/500 [00:18<00:37,  9.01epoch/s, loss=4.7e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  33%|â| 165/500 [00:19<00:37,  8.98epoch/s, loss=4.4e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  33%|â| 166/500 [00:19<00:36,  9.07epoch/s, loss=4.63e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  33%|â| 167/500 [00:19<00:36,  9.08epoch/s, loss=4.7e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|â| 168/500 [00:19<00:36,  9.09epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|â| 169/500 [00:19<00:36,  9.12epoch/s, loss=4.46e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|â| 169/500 [00:19<00:36,  9.12epoch/s, loss=4.54e-5\u001b[A2021-07-06 16:15:03 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:03 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:03 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  34%|â| 170/500 [00:19<00:37,  8.69epoch/s, loss=4.54e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|â| 171/500 [00:19<00:37,  8.86epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|â| 172/500 [00:19<00:36,  8.97epoch/s, loss=4.67e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  35%|â| 173/500 [00:20<00:36,  8.96epoch/s, loss=4.55e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  35%|â| 174/500 [00:20<00:36,  8.99epoch/s, loss=4.53e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  35%|â| 175/500 [00:20<00:35,  9.10epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  35%|â| 176/500 [00:20<00:35,  9.10epoch/s, loss=4.57e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  35%|â| 177/500 [00:20<00:35,  9.01epoch/s, loss=4.45e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|â| 178/500 [00:20<00:35,  9.11epoch/s, loss=4.56e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|â| 179/500 [00:20<00:35,  9.10epoch/s, loss=4.53e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|â| 179/500 [00:20<00:35,  9.10epoch/s, loss=4.59e-52021-07-06 16:15:04 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:04 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:04 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  36%|â| 180/500 [00:20<00:36,  8.70epoch/s, loss=4.59e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|â| 181/500 [00:20<00:36,  8.84epoch/s, loss=4.37e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|â| 182/500 [00:21<00:35,  8.85epoch/s, loss=4.68e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  37%|â| 183/500 [00:21<00:35,  8.82epoch/s, loss=4.76e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  37%|â| 184/500 [00:21<00:35,  8.88epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  37%|â| 185/500 [00:21<00:35,  8.93epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  37%|â| 186/500 [00:21<00:35,  8.91epoch/s, loss=4.54e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  37%|â| 187/500 [00:21<00:36,  8.67epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|â| 188/500 [00:21<00:36,  8.56epoch/s, loss=4.5e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|â| 189/500 [00:21<00:36,  8.57epoch/s, loss=4.41e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|â| 189/500 [00:21<00:36,  8.57epoch/s, loss=4.28e-52021-07-06 16:15:05 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:05 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:05 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  38%|â| 190/500 [00:21<00:38,  8.13epoch/s, loss=4.28e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|â| 191/500 [00:22<00:36,  8.40epoch/s, loss=4.42e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|â| 192/500 [00:22<00:36,  8.41epoch/s, loss=4.72e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  39%|â| 193/500 [00:22<00:36,  8.43epoch/s, loss=4.74e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  39%|â| 194/500 [00:22<00:36,  8.37epoch/s, loss=4.56e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  39%|â| 195/500 [00:22<00:36,  8.35epoch/s, loss=4.6e-5,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  39%|â| 196/500 [00:22<00:41,  7.29epoch/s, loss=4.61e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  39%|â| 197/500 [00:22<00:39,  7.73epoch/s, loss=4.46e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|â| 198/500 [00:22<00:38,  7.91epoch/s, loss=4.63e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|â| 199/500 [00:23<00:37,  8.09epoch/s, loss=4.53e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|â| 199/500 [00:23<00:37,  8.09epoch/s, loss=4.69e-52021-07-06 16:15:07 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:07 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:07 INFO     Evaluation took 0.01s seconds\n",
      "Training epochs on cpu:  40%|â| 200/500 [00:23<00:37,  8.03epoch/s, loss=4.69e-5\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|â| 201/500 [00:23<00:36,  8.24epoch/s, loss=4.75e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|â| 202/500 [00:23<00:35,  8.48epoch/s, loss=4.47e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  41%|â| 203/500 [00:23<00:34,  8.52epoch/s, loss=4.65e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  41%|â| 204/500 [00:23<00:34,  8.67epoch/s, loss=4.59e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  41%|â| 205/500 [00:23<00:33,  8.72epoch/s, loss=4.56e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  41%|â| 206/500 [00:23<00:33,  8.79epoch/s, loss=4.64e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  41%|â| 207/500 [00:23<00:32,  8.94epoch/s, loss=4.66e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|â| 208/500 [00:24<00:32,  9.03epoch/s, loss=4.47e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|â| 209/500 [00:24<00:32,  9.08epoch/s, loss=4.43e-5\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|â| 209/500 [00:24<00:32,  9.08epoch/s, loss=4.69e-52021-07-06 16:15:08 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:08 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:08 INFO     Evaluation took 0.01s seconds\n",
      "2021-07-06 16:15:08 INFO     Stopping early after 21 evaluations at epoch 210. The best result hits@10=0.9849246231155779 occurred at epoch 10.\n",
      "2021-07-06 16:15:08 INFO     => loading checkpoint '/var/folders/nv/ml84yvj11ns_bxrq3c40q2xc0000gn/T/tmpguqx5fzr'\n",
      "2021-07-06 16:15:08 INFO     => loaded checkpoint '/var/folders/nv/ml84yvj11ns_bxrq3c40q2xc0000gn/T/tmpguqx5fzr' stopped after having finished epoch 10\n",
      "Training epochs on cpu:  42%|â| 209/500 [00:24<00:33,  8.59epoch/s, loss=4.69e-5\n",
      "2021-07-06 16:15:08 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:08 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "Evaluating on cpu: 100%|ââââââââââââââââââ| 199/199 [00:00<00:00, 15.2ktriple/s]\n",
      "2021-07-06 16:15:08 INFO     Evaluation took 0.01s seconds\n",
      "\u001b[32m[I 2021-07-06 16:15:08,753]\u001b[0m Trial 0 finished with value: 0.9849246231155779 and parameters: {'model.embedding_dim': 128, 'loss.margin': 0.5, 'loss.margin_activation': 'relu', 'optimizer.lr': 0.06271895743070736, 'negative_sampler.num_negs_per_pos': 1, 'training.batch_size': 8192}. Best is trial 0 with value: 0.9849246231155779.\u001b[0m\n",
      "int power_two embedding_dim 256\n",
      "categorical None margin 8.5\n",
      "categorical None margin_activation softplus\n",
      "float log lr 0.08798465410241989\n",
      "<class 'int'> None num_negs_per_pos 1\n",
      "num_epochs not suggested\n",
      "int power_two batch_size 4096\n",
      "2021-07-06 16:15:08 WARNING  No random seed is specified. Setting to 2659122568.\n",
      "2021-07-06 16:15:08 WARNING  No cuda devices were available. The model runs on CPU\n",
      "2021-07-06 16:15:08 INFO     Creating inverse triples.\n",
      "Training epochs on cpu:   0%|                        | 0/500 [00:00<?, ?epoch/s]\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.31batch/s]\u001b[A\n",
      "Training epochs on cpu:   0%| | 1/500 [00:00<01:24,  5.93epoch/s, loss=0.00267, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.28batch/s]\u001b[A\n",
      "Training epochs on cpu:   0%| | 2/500 [00:00<01:24,  5.90epoch/s, loss=0.00256, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.24batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 3/500 [00:00<01:24,  5.88epoch/s, loss=0.00249, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.79batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 4/500 [00:00<01:22,  6.01epoch/s, loss=0.00248, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.78batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 5/500 [00:00<01:27,  5.68epoch/s, loss=0.00244, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  5.87batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 6/500 [00:01<01:34,  5.24epoch/s, loss=0.00239, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.17batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%| | 7/500 [00:01<01:30,  5.43epoch/s, loss=0.00244, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.91batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 8/500 [00:01<01:29,  5.49epoch/s, loss=0.0024, p\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.41batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 9/500 [00:01<01:29,  5.46epoch/s, loss=0.00234, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.44batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 9/500 [00:01<01:29,  5.46epoch/s, loss=0.00237, 2021-07-06 16:15:10 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:10 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:10 INFO     Evaluation took 0.02s seconds\n",
      "2021-07-06 16:15:10 INFO     => Saved checkpoint after having finished epoch 10.\n",
      "Training epochs on cpu:   2%| | 10/500 [00:01<01:30,  5.44epoch/s, loss=0.00237,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.59batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 11/500 [00:01<01:27,  5.61epoch/s, loss=0.00231,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.82batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%| | 12/500 [00:02<01:26,  5.61epoch/s, loss=0.00233,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.43batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 13/500 [00:02<01:24,  5.73epoch/s, loss=0.0023, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.80batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 14/500 [00:02<01:22,  5.88epoch/s, loss=0.00228,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.31batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 15/500 [00:02<01:22,  5.90epoch/s, loss=0.00223,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.91batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 16/500 [00:02<01:23,  5.82epoch/s, loss=0.0022, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.18batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%| | 17/500 [00:02<01:22,  5.84epoch/s, loss=0.0022, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.26batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 18/500 [00:03<01:22,  5.81epoch/s, loss=0.00216,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.09batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 19/500 [00:03<01:22,  5.80epoch/s, loss=0.00212,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.37batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 19/500 [00:03<01:22,  5.80epoch/s, loss=0.00211,2021-07-06 16:15:12 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:12 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:12 INFO     Evaluation took 0.02s seconds\n",
      "2021-07-06 16:15:12 INFO     => Saved checkpoint after having finished epoch 20.\n",
      "Training epochs on cpu:   4%| | 20/500 [00:03<01:25,  5.65epoch/s, loss=0.00211,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.62batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 21/500 [00:03<01:22,  5.79epoch/s, loss=0.00207,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.65batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%| | 22/500 [00:03<01:20,  5.90epoch/s, loss=0.00206,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.52batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 23/500 [00:04<01:19,  5.96epoch/s, loss=0.00203,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.05batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 24/500 [00:04<01:20,  5.92epoch/s, loss=0.00197,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.51batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 25/500 [00:04<01:19,  5.97epoch/s, loss=0.00196,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.41batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 26/500 [00:04<01:18,  6.00epoch/s, loss=0.00191,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.55batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%| | 27/500 [00:04<01:18,  6.05epoch/s, loss=0.0019, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.26batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 28/500 [00:04<01:18,  6.02epoch/s, loss=0.00188,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.05batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 29/500 [00:05<01:19,  5.94epoch/s, loss=0.00182,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.46batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 29/500 [00:05<01:19,  5.94epoch/s, loss=0.00178,2021-07-06 16:15:14 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:14 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:14 INFO     Evaluation took 0.02s seconds\n",
      "2021-07-06 16:15:14 INFO     => Saved checkpoint after having finished epoch 30.\n",
      "Training epochs on cpu:   6%| | 30/500 [00:05<01:21,  5.76epoch/s, loss=0.00178,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.03batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 31/500 [00:05<01:21,  5.75epoch/s, loss=0.00176,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.10batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%| | 32/500 [00:05<01:21,  5.74epoch/s, loss=0.00172,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.99batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 33/500 [00:05<01:21,  5.76epoch/s, loss=0.00168,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.35batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 34/500 [00:05<01:20,  5.82epoch/s, loss=0.00168,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.55batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 35/500 [00:06<01:18,  5.91epoch/s, loss=0.00165,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.16batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 36/500 [00:06<01:18,  5.91epoch/s, loss=0.0016, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.40batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%| | 37/500 [00:06<01:18,  5.91epoch/s, loss=0.00159,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.54batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 38/500 [00:06<01:17,  5.97epoch/s, loss=0.00157,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.26batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 39/500 [00:06<01:17,  5.94epoch/s, loss=0.00149,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.23batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 39/500 [00:06<01:17,  5.94epoch/s, loss=0.00149,2021-07-06 16:15:15 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:15 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:15 INFO     Evaluation took 0.02s seconds\n",
      "Training epochs on cpu:   8%| | 40/500 [00:06<01:20,  5.71epoch/s, loss=0.00149,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.35batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 41/500 [00:07<01:19,  5.81epoch/s, loss=0.00148,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.26batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%| | 42/500 [00:07<01:18,  5.86epoch/s, loss=0.00148,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.33batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 43/500 [00:07<01:17,  5.91epoch/s, loss=0.00141,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.35batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 44/500 [00:07<01:16,  5.94epoch/s, loss=0.00138,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.17batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 45/500 [00:07<01:16,  5.93epoch/s, loss=0.00137,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.26batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 46/500 [00:07<01:16,  5.90epoch/s, loss=0.00136,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.99batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%| | 47/500 [00:08<01:17,  5.87epoch/s, loss=0.00135,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.14batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 48/500 [00:08<01:17,  5.87epoch/s, loss=0.00133,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.39batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 49/500 [00:08<01:16,  5.90epoch/s, loss=0.00132,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.33batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 49/500 [00:08<01:16,  5.90epoch/s, loss=0.00129,2021-07-06 16:15:17 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:17 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:17 INFO     Evaluation took 0.02s seconds\n",
      "Training epochs on cpu:  10%| | 50/500 [00:08<01:18,  5.73epoch/s, loss=0.00129,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.04batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 51/500 [00:08<01:17,  5.76epoch/s, loss=0.00127,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.36batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%| | 52/500 [00:08<01:19,  5.67epoch/s, loss=0.00124,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.98batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 53/500 [00:09<01:18,  5.69epoch/s, loss=0.00125,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.46batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 54/500 [00:09<01:16,  5.80epoch/s, loss=0.00123,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.48batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 55/500 [00:09<01:15,  5.89epoch/s, loss=0.00125,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.30batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 56/500 [00:09<01:15,  5.91epoch/s, loss=0.00121,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.85batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%| | 57/500 [00:09<01:15,  5.86epoch/s, loss=0.0012, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.29batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 58/500 [00:09<01:15,  5.89epoch/s, loss=0.0012, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.27batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 59/500 [00:10<01:14,  5.91epoch/s, loss=0.00117,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.20batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 59/500 [00:10<01:14,  5.91epoch/s, loss=0.00116,2021-07-06 16:15:19 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:19 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:19 INFO     Evaluation took 0.02s seconds\n",
      "Training epochs on cpu:  12%| | 60/500 [00:10<01:18,  5.63epoch/s, loss=0.00116,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.07batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 61/500 [00:10<01:17,  5.69epoch/s, loss=0.00112,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  6.33batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%| | 62/500 [00:10<01:21,  5.38epoch/s, loss=0.00113,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.53batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 63/500 [00:10<01:20,  5.43epoch/s, loss=0.0012, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  6.77batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 64/500 [00:11<01:21,  5.33epoch/s, loss=0.00111,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.91batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 65/500 [00:11<01:19,  5.45epoch/s, loss=0.0011, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.28batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 66/500 [00:11<01:17,  5.60epoch/s, loss=0.00112,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.11batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|â| 67/500 [00:11<01:16,  5.68epoch/s, loss=0.0011, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.61batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 68/500 [00:11<01:16,  5.63epoch/s, loss=0.00111,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.94batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 69/500 [00:11<01:15,  5.68epoch/s, loss=0.00108,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  7.62batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 69/500 [00:12<01:15,  5.68epoch/s, loss=0.00107,2021-07-06 16:15:21 INFO     Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "2021-07-06 16:15:21 INFO     No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "2021-07-06 16:15:21 INFO     Evaluation took 0.02s seconds\n",
      "Training epochs on cpu:  14%|â| 70/500 [00:12<01:18,  5.47epoch/s, loss=0.00107,\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.22batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 71/500 [00:12<01:16,  5.59epoch/s, loss=0.00104,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.20batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|â| 72/500 [00:12<01:15,  5.68epoch/s, loss=0.0011, \u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.41batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 73/500 [00:12<01:13,  5.79epoch/s, loss=0.00106,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.35batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 74/500 [00:12<01:12,  5.86epoch/s, loss=0.00109,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  8.03batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 75/500 [00:13<01:12,  5.85epoch/s, loss=0.00104,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|âââââââââââââââââ| 1/1 [00:00<00:00,  6.83batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|â| 76/500 [00:13<01:16,  5.56epoch/s, loss=0.00103,\u001b[A\n",
      "Training batches on cpu:   0%|                         | 0/1 [00:00<?, ?batch/s]\u001b[A^C\n"
     ]
    }
   ],
   "source": [
    "with open(\"ablation_config.json\", \"w\") as f:\n",
    "    json.dump(ablation_config, f)\n",
    "\n",
    "!pykeen experiments ablation ./ablation_config.json -d ./ablation_tests \n",
    "\n",
    "#--dry-run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46537c05-802b-4a6a-932d-a52e328eebdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
